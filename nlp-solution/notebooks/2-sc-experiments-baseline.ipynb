{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/szuyaochien/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-25 07:27:22,666 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n",
      "2021-04-25 07:27:22,667 INFO sqlalchemy.engine.base.Engine ()\n",
      "2021-04-25 07:27:22,668 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n",
      "2021-04-25 07:27:22,668 INFO sqlalchemy.engine.base.Engine ()\n",
      "2021-04-25 07:27:22,670 INFO sqlalchemy.engine.base.Engine PRAGMA main.table_info(\"SELECT * FROM train\")\n",
      "2021-04-25 07:27:22,670 INFO sqlalchemy.engine.base.Engine ()\n",
      "2021-04-25 07:27:22,671 INFO sqlalchemy.engine.base.Engine PRAGMA temp.table_info(\"SELECT * FROM train\")\n",
      "2021-04-25 07:27:22,672 INFO sqlalchemy.engine.base.Engine ()\n",
      "2021-04-25 07:27:22,672 INFO sqlalchemy.engine.base.Engine SELECT * FROM train\n",
      "2021-04-25 07:27:22,673 INFO sqlalchemy.engine.base.Engine ()\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite:///../data/data.db', echo=True)\n",
    "conn = engine.connect()\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM train\",conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5698, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "824.company-brand.general-satisfaction.0                   2682\n",
       "824.account-management.account-access.0                     847\n",
       "824.company-brand.convenience.0                             799\n",
       "824.online-experience.updates-versions.0                    565\n",
       "824.company-brand.competitor.0                              520\n",
       "824.account-management.fingerprint-facial-recognition.0     199\n",
       "824.staff-support.agent-named.0                              32\n",
       "824.staff-support.email.0                                    17\n",
       "824.online-experience.language.0                             13\n",
       "824.purchase-booking-experience.choice-variety.0             11\n",
       "824.logistics-rides.speed.0                                   6\n",
       "824.attributes.size-fit.0                                     3\n",
       "824.logistics-rides.order-accuracy.0                          2\n",
       "824.attributes.cleanliness.0                                  1\n",
       "824.attributes.taste-flavour.0                                1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove the label < 20 posts\n",
    "df = df[~df['label'].isin([\n",
    "                      '824.staff-support.email.0',\n",
    "                      '824.online-experience.language.0',\n",
    "                      '824.purchase-booking-experience.choice-variety.0',\n",
    "                      '824.logistics-rides.speed.0',\n",
    "                      '824.attributes.size-fit.0',\n",
    "                      '824.logistics-rides.order-accuracy.0',\n",
    "                      '824.attributes.taste-flavour.0',\n",
    "                      '824.attributes.cleanliness.0'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.merge(df['comment'],pd.get_dummies(df['label']),left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label number: 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Label number:\", len(label_df.drop('comment',axis=1).columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_punctuation_marks(text):\n",
    "    return re.sub(r'[^\\w\\s]',\" \",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df['clean_comment'] = label_df['comment'].apply(remove_punctuation_marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df['clean_comment'] = label_df['clean_comment'].map(lambda x: ' '.join(i for i in x.split() if len(i)>1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. train-val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(label_df,test_size=0.1,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5079, 9), (565, 9))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Baseline model: Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer(ngram_range=(1, 2),max_df=0.9, min_df=5,stop_words='english',lowercase=True)),\n",
    "#     ('clf',MultiOutputClassifier(estimator=LogisticRegression()))\n",
    "    ('clf',MultiOutputClassifier(estimator=LogisticRegression(class_weight='balanced'))) ## added class weight as the labels are imbalanced. ##\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base.fit(train['clean_comment'],train.drop(['clean_comment','comment'],axis=1).values)\n",
    "prediction = model_base.predict(val['clean_comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted output:\n",
      "                                                          precision    recall  f1-score   support\n",
      "\n",
      "                824.account-management.account-access.0       0.78      0.31      0.44        95\n",
      "824.account-management.fingerprint-facial-recognition.0       1.00      0.07      0.13        14\n",
      "                         824.company-brand.competitor.0       0.67      0.21      0.31        68\n",
      "                        824.company-brand.convenience.0       0.62      0.32      0.42        72\n",
      "               824.company-brand.general-satisfaction.0       0.74      0.82      0.78       269\n",
      "               824.online-experience.updates-versions.0       0.86      0.41      0.55        44\n",
      "                        824.staff-support.agent-named.0       0.00      0.00      0.00         3\n",
      "\n",
      "                                              micro avg       0.74      0.54      0.62       565\n",
      "                                              macro avg       0.67      0.30      0.38       565\n",
      "                                           weighted avg       0.74      0.54      0.58       565\n",
      "                                            samples avg       0.53      0.54      0.53       565\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/szuyaochien/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/szuyaochien/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Unweighted output:\\n\", classification_report(val.drop(['clean_comment','comment'],axis=1),\n",
    "                                                    prediction,\n",
    "                                                    target_names=val.drop(['clean_comment','comment'],axis=1).columns)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted output:\n",
      "                                                          precision    recall  f1-score   support\n",
      "\n",
      "                824.account-management.account-access.0       0.61      0.73      0.66        95\n",
      "824.account-management.fingerprint-facial-recognition.0       0.39      0.86      0.53        14\n",
      "                         824.company-brand.competitor.0       0.56      0.79      0.66        68\n",
      "                        824.company-brand.convenience.0       0.52      0.74      0.61        72\n",
      "               824.company-brand.general-satisfaction.0       0.74      0.83      0.78       269\n",
      "               824.online-experience.updates-versions.0       0.69      0.95      0.80        44\n",
      "                        824.staff-support.agent-named.0       0.17      0.67      0.27         3\n",
      "\n",
      "                                              micro avg       0.63      0.81      0.71       565\n",
      "                                              macro avg       0.52      0.80      0.62       565\n",
      "                                           weighted avg       0.65      0.81      0.72       565\n",
      "                                            samples avg       0.67      0.81      0.72       565\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/szuyaochien/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Weighted output:\\n\",classification_report(val.drop(['clean_comment','comment'],axis=1),\n",
    "                                                 prediction,\n",
    "                                                 target_names=val.drop(['clean_comment','comment'],axis=1).columns)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/model_base.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model_base,\"../models/model_base.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
